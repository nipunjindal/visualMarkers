{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "plt.rcParams['xtick.major.pad']='16'\n",
    "\n",
    "def count_params():\n",
    "    \"\"\"Count the number of parameters in the current TensorFlow graph \"\"\"\n",
    "    param_count = np.sum([np.prod(x.get_shape().as_list()) for x in tf.global_variables()])\n",
    "    return param_count\n",
    "\n",
    "\n",
    "def get_session():\n",
    "    config = tf.ConfigProto()\n",
    "    config.log_device_placement    = True\n",
    "#     config.gpu_options.allow_growth = True\n",
    "    session = tf.Session(config=config)\n",
    "    return session\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "code_length = 10\n",
    "output_image = 32\n",
    "\n",
    "data = np.random.choice([-1, 1], size=(20000, 10))\n",
    "input_data = data[0:18000]\n",
    "val_data = data[-2000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#style calculation\n",
    "import vgg19\n",
    "\n",
    "# gram matrix per layer\n",
    "def gram_matrix(x):\n",
    "    assert isinstance(x, tf.Tensor)\n",
    "    b, h, w, ch = x.get_shape().as_list()\n",
    "    features = tf.reshape(x, [-1, h*w, ch])\n",
    "    gram = tf.matmul(features, features, transpose_b=True)/tf.constant(ch*w*h, tf.float32)\n",
    "    return gram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = get_session()\n",
    "\n",
    "# synthesizer network\n",
    "_input = tf.placeholder(tf.float32, [None, code_length])\n",
    "isTraining = tf.placeholder(tf.bool)\n",
    "\n",
    "# dense_layer = tf.layers.dense(input_, output_image * output_image * 3, activation=tf.nn.relu, name='dense1')\n",
    "sy_dl1 = tf.layers.dense(_input, 8 * 8 * 64, activation=tf.nn.relu, name='dense1') \n",
    "sy_dl1_r = tf.reshape(sy_dl1, (-1, 8, 8, 64)) # [-1, 8, 8, 64]\n",
    "\n",
    "# [N, 8, 8, 128] x [3, 3] = [N, 8, 8, 64]\n",
    "sy_cn1 = tf.layers.conv2d(sy_dl1_r, 64, 3, 1, padding=\"same\", activation=tf.nn.relu)\n",
    "\n",
    "# [N, 8, 8, 64] x [3, 3] = [N, 8, 8, 32]\n",
    "sy_cn2 = tf.layers.conv2d(sy_cn1, 32, 3, 1, padding=\"same\", activation=tf.nn.relu)\n",
    "\n",
    "# [N, 8, 8, 32] x [3, 3] = [N, 16, 16, 32]\n",
    "sy_cnt1 = tf.layers.conv2d_transpose(sy_cn2, 32, 3, 2, padding=\"same\")\n",
    "\n",
    "# [N, 16, 16, 32] x [3, 3] = [N, 16, 16, 64]\n",
    "sy_cn3 = tf.layers.conv2d(sy_cnt1, 64, 3, 1, padding=\"same\", activation=tf.nn.relu)\n",
    "\n",
    "# [N, 16, 16, 64] x [3, 3] = [N, 16, 16, 32]\n",
    "sy_cn4 = tf.layers.conv2d(sy_cn3, 32, 3, 1, padding=\"same\", activation=tf.nn.relu)\n",
    "\n",
    "# [N, 16, 16, 32] x [3, 3] = [N, 32, 32, 3]\n",
    "sy_output_image = tf.layers.conv2d_transpose(sy_cn4, 3, 3, 2, padding=\"same\")\n",
    "\n",
    "tf.summary.image('marker', sy_output_image)\n",
    "\n",
    "#recognizer network\n",
    "conv1 = tf.layers.conv2d(sy_output_image, 96, [5, 5], padding='same', name='conv1') # [32, 32, 96]\n",
    "kernel_conv1 = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, 'conv1/kernel')[0]\n",
    "bias_conv1 = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, 'conv1/bias')[0]\n",
    "tf.summary.histogram('conv1/kernel', kernel_conv1)\n",
    "tf.summary.histogram('conv1/bias', bias_conv1)\n",
    "\n",
    "pool1 = tf.layers.max_pooling2d(conv1, [2, 2], 2, padding='valid') # [16, 16, 96]\n",
    "batch1 = tf.layers.batch_normalization(pool1, axis=3, training=isTraining)\n",
    "relu1 = tf.nn.relu(batch1) # [16, 16, 96]\n",
    "\n",
    "conv2 = tf.layers.conv2d(relu1, 96, [5, 5], padding='same', name='conv2') # [16, 16, 96]\n",
    "kernel_conv2 = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, 'conv2/kernel')[0]\n",
    "bias_conv2 = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, 'conv2/bias')[0]\n",
    "tf.summary.histogram('conv2/kernel', kernel_conv2)\n",
    "tf.summary.histogram('conv2/bias', bias_conv2)\n",
    "\n",
    "pool2 = tf.layers.max_pooling2d(conv2, [2, 2], 2, padding='valid') # [8, 8, 96]\n",
    "batch2 = tf.layers.batch_normalization(pool2, axis=3, training=isTraining)\n",
    "relu2 = tf.nn.relu(batch2) # [8, 8, 96]\n",
    "\n",
    "conv3 = tf.layers.conv2d(relu2, 96, [5, 5], padding='same', name='conv3') # [8, 8, 96]\n",
    "kernel_conv3 = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, 'conv3/kernel')[0]\n",
    "bias_conv3 = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, 'conv3/bias')[0]\n",
    "tf.summary.histogram('conv3/kernel', kernel_conv3)\n",
    "tf.summary.histogram('conv3/bias', bias_conv3)\n",
    "\n",
    "pool3 = tf.layers.max_pooling2d(conv3, [2, 2], 2, padding='valid') # [4, 4, 96]\n",
    "batch3 = tf.layers.batch_normalization(pool3, axis=3, training=isTraining)\n",
    "relu3 = tf.nn.relu(batch3) # [4, 4, 96]\n",
    "\n",
    "flat_relu3 = tf.reshape(relu3, (-1, 4 * 4 * 96))\n",
    "fc1 = tf.layers.dense(flat_relu3, 192)\n",
    "fc2 = tf.layers.dense(fc1, code_length)\n",
    "\n",
    "vgg_s = vgg19.Vgg19()\n",
    "np_target_style_image = np.asarray(plt.imread('style.png'))\n",
    "target_style_image = tf.constant(np_target_style_image[np.newaxis, :, :, 0:3])\n",
    "vgg_s.build(tf.image.resize_images(target_style_image, (224, 224)))\n",
    "feature_ = [vgg_s.conv1_2, vgg_s.conv2_2, vgg_s.conv3_3, vgg_s.conv4_3, vgg_s.conv5_3]\n",
    "gram_ = [gram_matrix(l) for l in feature_]\n",
    "\n",
    "vgg = vgg19.Vgg19()\n",
    "vgg.build(tf.image.resize_images(sy_output_image[0:1,:,:,:], (224, 224)))\n",
    "feature = [vgg.conv1_2, vgg.conv2_2, vgg.conv3_3, vgg.conv4_3, vgg.conv5_3]\n",
    "gram = [gram_matrix(l) for l in feature]\n",
    "\n",
    "style_loss = tf.zeros(1, tf.float32)\n",
    "for g, g_ in zip(gram, gram_):\n",
    "    style_loss += 1e1 * tf.reduce_mean(tf.subtract(g, g_) ** 2)\n",
    "\n",
    "# loss function is element wise sigmoid\n",
    "# mean_loss = tf.losses.mean_squared_error(input_, fc2)\n",
    "# sigmoid_loss = tf.losses.sigmoid_cross_entropy(tf.cast(input_, tf.int32), fc2)\n",
    "mean_loss = tf.losses.mean_squared_error(_input, fc2)\n",
    "# sigmoid_loss = -tf.multiply(tf.reduce_mean(tf.sigmoid(tf.multiply(input_, fc2))), tf.constant(1.))\n",
    "\n",
    "loss = mean_loss + style_loss\n",
    "tf.summary.scalar('mean_loss', mean_loss)\n",
    "tf.summary.scalar('style_loss', style_loss)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.05)\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter('./train', sess.graph)\n",
    "# batch normalization in tensorflow requires this extra dependency\n",
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(extra_update_ops):\n",
    "    train = optimizer.minimize(loss)\n",
    "\n",
    "\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#missing Trainable batch norm thingy\n",
    "for i in tqdm(range(200 * 90)):\n",
    "    batch_ = np.random.randint(9000, size=200)\n",
    "    x = sess.run([train, merged], feed_dict={_input : input_data[batch_, :], isTraining : True})\n",
    "    if i % 50 == 0:\n",
    "        writer.add_summary(x[1], i)\n",
    "\n",
    "    if i % 500 == 0:\n",
    "        x = sess.run([loss], feed_dict={_input : val_data, isTraining : False})\n",
    "        print('loss: ', x[0])\n",
    "        \n",
    "        #print a sample output\n",
    "        check_data = np.random.choice([-1, 1], size=(1, 10))\n",
    "        #print(check_data[0])\n",
    "        image_output = sess.run([sy_output_image], feed_dict={_input : check_data, isTraining : False})\n",
    "        image_output1 = np.reshape(image_output[0], (output_image, output_image, 3))\n",
    "        plt.figure(figsize=(4, 4))\n",
    "        plt.imshow(image_output1)\n",
    "        plt.show(image_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "check_data = np.random.choice([-1, 1], size=(1, 10))\n",
    "print(check_data[0])\n",
    "image_output = sess.run([dense_layer1], feed_dict={input_ : check_data, isTraining : False})\n",
    "print(image_output[0].shape)\n",
    "# print(np.sign(image_output[0][0]))\n",
    "# image_output1 = np.reshape(image_output[0], (output_image, output_image, 3))\n",
    "# plt.figure(figsize=(4, 4))\n",
    "# plt.imshow(image_output1)\n",
    "\n",
    "# plt.show(image_output)\n",
    "# print(np.sign(image_output[0][0]))\n",
    "# image_output1 = np.reshape(image_output[0], (output_image, output_image, 3))\n",
    "# plt.imshow(image_output1)\n",
    "\n",
    "# print(sess.run([fc2], feed_dict={input_ : check_data, isTraining: False}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
